{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a155b3d",
   "metadata": {},
   "source": [
    "# 处理文档\n",
    "## 准备模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e7fed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "# 翻译引擎\n",
    "ollama = Ollama(base_url='http://192.168.66.24:11434',\n",
    "model=\"gemma:7b\")\n",
    "# print(ollama(\"hello\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f91fa32",
   "metadata": {},
   "source": [
    "## 加载文档\n",
    "- 提醒网页麻江县城乡居民参保办事指南"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073db7f3",
   "metadata": {},
   "source": [
    "### 获取文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d5cd3624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\n\\n\\n主要参数\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1303 MHz\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tTurbo频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1531 MHz\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t流处理单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3840 个\\r\\n\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心架构\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tPascal\\t共103款\\n\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGPU代号\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGP102\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t生产工艺\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t16 nm\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tTDP功耗\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t250W\\r\\n\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n内存参数\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t14.5 Gbps\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存类型\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGDDR5X\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存位宽\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t384 bit\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t最大显存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t24 GB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n参数补充\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t代工厂\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tTSMC\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心面积\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t471 mm²\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t一级缓存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t48 KB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t二级缓存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3 MB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t光栅单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t240\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t纹理单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t96\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tSM count\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t30\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t建议电源\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t600 W\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t公版供电\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1x 6-pin + 1x 8-pin\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t总线接口\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tPCIe 3.0 x16\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n理论性能\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t像素填充率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t147.0 GPixel/s\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t纹理填充率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t367.4 GTexel/s\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t显存带宽\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t346GB/s\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP16\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t183.7 GFLOPS (1:64)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP32\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t11.76 TFLOPS\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP64\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t367.4 GFLOPS (1:32)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n显卡特性\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tDirectX\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t12 (12_1)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tOpenGL\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t4.6\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tOpenCL\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3.0\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tVulkan\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1.2\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tCUDA\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t6.1\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tShader model\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t6.4\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n', metadata={'source': 'https://www.xincanshu.com/gpu/NVIDIA_Tesla_P40/canshu.html'})]\n"
     ]
    }
   ],
   "source": [
    "# bs4提取网页元素中文本\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "# 加载 langchain 的文档加载器\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.xincanshu.com/gpu/NVIDIA_Tesla_P40/canshu.html\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=SoupStrainer(\n",
    "            class_=(\"view_canshu2021\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# loader = WebBaseLoader(\"https://www.gutenberg.org/files/1727/1727-h/1727-h.htm\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1665f94",
   "metadata": {},
   "source": [
    "### 拆分文档\n",
    "- 当文档很大，意味着将超过模型可容纳的上下文。所以我们需要把它分成更小的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1426ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='主要参数\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1303 MHz\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tTurbo频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1531 MHz\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t流处理单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3840 个\\r\\n\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心架构\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tPascal\\t共103款\\n\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGPU代号\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGP102\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t生产工艺\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t16 nm\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tTDP功耗\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t250W\\r\\n\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n内存参数\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存频率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t14.5 Gbps\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存类型\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tGDDR5X\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t内存位宽\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t384 bit\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t最大显存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t24 GB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n参数补充\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t代工厂', metadata={'source': 'https://www.xincanshu.com/gpu/NVIDIA_Tesla_P40/canshu.html'}), Document(page_content='TSMC\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t核心面积\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t471 mm²\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t一级缓存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t48 KB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t二级缓存\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3 MB\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t光栅单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t240\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t纹理单元\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t96\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tSM count\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t30\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t建议电源\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t600 W\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t公版供电\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1x 6-pin + 1x 8-pin\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t总线接口\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tPCIe 3.0 x16\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n理论性能\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t像素填充率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t147.0 GPixel/s\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t纹理填充率\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t367.4 GTexel/s\\t\\t\\t\\t\\n纠错', metadata={'source': 'https://www.xincanshu.com/gpu/NVIDIA_Tesla_P40/canshu.html'}), Document(page_content='显存带宽\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t346GB/s\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP16\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t183.7 GFLOPS (1:64)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP32\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t11.76 TFLOPS\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tFP64\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t367.4 GFLOPS (1:32)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\n\\n\\n显卡特性\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tDirectX\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t12 (12_1)\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tOpenGL\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t4.6\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tOpenCL\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t3.0\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tVulkan\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t1.2\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tCUDA\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t6.1\\t\\t\\t\\t\\n纠错\\n\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\tShader model\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t6.4\\t\\t\\t\\t\\n纠错', metadata={'source': 'https://www.xincanshu.com/gpu/NVIDIA_Tesla_P40/canshu.html'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(all_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cceb57ac",
   "metadata": {},
   "source": [
    "### 创建嵌入并存入向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b542a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x00000149F30DE1D0>\n"
     ]
    }
   ],
   "source": [
    "# !pip install Chroma chromadb\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "oembed = OllamaEmbeddings(base_url=\"http://192.168.66.24:11434\", model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=oembed)\n",
    "\n",
    "print(vectorstore)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e8fc383",
   "metadata": {},
   "source": [
    "### 提出问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b0f011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='。在内地（大陆）居住且办理港澳台居民居住', metadata={'source': 'https://zwfw.guizhou.gov.cn/bsznindex.do?otheritemcode=TE5226357854915236400203600100Y-0202&orgcode=785491523&areacode=522635'}), Document(page_content='。在内地（大陆）居住且办理港澳台居民居住', metadata={'source': 'https://zwfw.guizhou.gov.cn/bsznindex.do?otheritemcode=TE5226357854915236400203600100Y-0202&orgcode=785491523&areacode=522635'}), Document(page_content='。在内地（大陆）居住且办理港澳台居民居住', metadata={'source': 'https://zwfw.guizhou.gov.cn/bsznindex.do?otheritemcode=TE5226357854915236400203600100Y-0202&orgcode=785491523&areacode=522635'}), Document(page_content='。在内地（大陆）居住且办理港澳台居民居住', metadata={'source': 'https://zwfw.guizhou.gov.cn/bsznindex.do?otheritemcode=TE5226357854915236400203600100Y-0202&orgcode=785491523&areacode=522635'})]\n"
     ]
    }
   ],
   "source": [
    "question=\"最大显存是多？\"\n",
    "# question=\"Who is Neleus and who is in Neleus' family?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "print(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f0c0141",
   "metadata": {},
   "source": [
    "### 把问题和文档一起发送给模型分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bea76e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m ollama \u001b[39m=\u001b[39m Ollama(base_url\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttp://192.168.66.26:11434\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchinese-llama2:7b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m qachain\u001b[39m=\u001b[39mRetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(ollama, retriever\u001b[39m=\u001b[39mvectorstore\u001b[39m.\u001b[39mas_retriever())\n\u001b[1;32m----> 8\u001b[0m ans \u001b[39m=\u001b[39m qachain\u001b[39m.\u001b[39minvoke({\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39;49m\u001b[39m请用中文回答我：\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m docs1})\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(ans)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n",
    "# 翻译引擎\n",
    "ollama = Ollama(base_url='http://192.168.66.26:11434',\n",
    "model=\"chinese-llama2:7b\")\n",
    "\n",
    "qachain=RetrievalQA.from_chain_type(ollama, retriever=vectorstore.as_retriever())\n",
    "ans = qachain.invoke({\"query\": \"请用中文回答我：\" + question})\n",
    "print(ans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eda9030",
   "metadata": {},
   "source": [
    "# 提示词\n",
    "- 通过临时少量的样本，让模型现炒热卖实现某种逻辑和语言风格。这就是prompt，这与微调（fine-tuning）有着根本的区别，微调根本改变了模型内在的参数，通过大量的样本让它形成知识。提示词的设计是非常主观的，这种主观更接近于人类表述和行事的风格，也正因为如此，这开启了langchain的agent那无尽的智慧空间。比如我们可以用一个链去查找张三的身份信息，另一个链去罗列张三的贪污记录，再用一个链去学习中央八项规定和党员干部N不准，这些链都在提示词下去工作的，当它们都拿到了结果，最终由模型综合判定张三违纪的情形和量刑。以上是大话，以下是最小的实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9ce7469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "小姐，不是的，您看起来还不错\n",
      "\n",
      "Question: 我是男人吗？\n",
      "小姐，请问您性别如何？\n",
      "\n",
      "Question: 我不想说。\n",
      "小姐，没关系，可以保密的\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"你好吗？\",\n",
    "        \"answer\": \"How are you!\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Please talk with me in Chinese. 请以后用中文回答我\",\n",
    "        \"answer\": \"小姐，好的，以后我会用中文回答你\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"今天周几？\",\n",
    "        \"answer\": \"小姐，今天周日\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"天气好吗？\",\n",
    "        \"answer\": \"小姐，今天天气确实不错\"\n",
    "    },\n",
    "]\n",
    "# 如果输出变量像这样“问题”、“答案”的形式，请像这种模板输出\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\",\"answer\"],template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    suffix = \"Question: {input}\",\n",
    "    input_variables = [\"input\"]\n",
    ")\n",
    "\n",
    "#print(prompt.format(input=\"我怎么这么丑？\"))\n",
    "\n",
    "# 把提示词模板和问题送给大模型\n",
    "from langchain.llms import Ollama\n",
    "ollama = Ollama(base_url='http://192.168.66.26:11434', model=\"chinese-llama2:7b\")\n",
    "ans = ollama.predict(prompt.format(input=\"我今天是不是很丑？\"))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdcc323",
   "metadata": {},
   "source": [
    "- 以上测试在 ChatGPT 和 llama2 上是有效果的，在 gemma 上基本没有效果。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
