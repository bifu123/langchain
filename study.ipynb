{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94943277-35c2-4500-a421-4ca8f0e72e50",
   "metadata": {},
   "source": [
    "## langchain调用gemini api作为模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe119545-67f5-4e01-9a18-0291015519f3",
   "metadata": {},
   "source": [
    "- 安装langchain-google-genai包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67241b58-cfe9-4737-b56f-f817e54c215c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c80792-1e0f-4f93-8f3a-34e73776ecb1",
   "metadata": {},
   "source": [
    "- 导入包，执行链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36816862-e0e0-46a7-b938-5a15902703d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# 将GOOGLE_API_KEY加载到环境变量中\n",
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBgKE09ReHYbG2lqC_YmdsbEjF8yQGWrGM'\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc355bd3-d2ea-45e4-994d-8662bfca9e4a",
   "metadata": {},
   "source": [
    "- 而普通的聊天API是这样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986dad35-cf37-4838-8f07-4d14d7a30a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY='AIzaSyBgKE09ReHYbG2lqC_YmdsbEjF8yQGWrGM'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
    "prompt_parts = [\n",
    "    \"Write a rand number between 90-95\",\n",
    "]\n",
    "response = model.generate_content(prompt_parts)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a3a70-63f2-45cf-8d1f-9582001a27a0",
   "metadata": {},
   "source": [
    "- 让我再来试一下它的图像功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b7184-0deb-4d81-aa7a-5dc68d56b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What's in this image?\",\n",
    "        },  # You can optionally provide text parts\n",
    "        {\"type\": \"image_url\", \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/P.t.altaica_Tomak_Male.jpg/800px-P.t.altaica_Tomak_Male.jpg\"},\n",
    "    ]\n",
    ")\n",
    "llm.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7c129-fffe-41dd-8dd2-afd7a2db4afe",
   "metadata": {},
   "source": [
    "- 它说有一只老虎在雪地上，是的，它是正确的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1232fd1-67b9-4ae1-a4d1-cded47007bdf",
   "metadata": {},
   "source": [
    "# gemini rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f119ca-319e-4c55-ad14-eb80de7df63a",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efdde338-38bd-4285-94bd-1e1738d173c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档加工\n",
    "from langchain_community.document_loaders import PyPDFLoader #PDF加载器\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # 分割文档\n",
    "from langchain_community.vectorstores import Chroma # 量化文档数据库\n",
    "\n",
    "# ollama模型\n",
    "from langchain_community.embeddings import OllamaEmbeddings # 量化文档\n",
    "from langchain_community.llms import Ollama #模型\n",
    "\n",
    "# 链结构\n",
    "from langchain.chains import RetrievalQA #链\n",
    "\n",
    "# gemini模型\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 语义检索\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa74971-ff22-4d32-b9f0-3f55e3a15306",
   "metadata": {},
   "source": [
    "## 定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc1b3b1-39f8-48f4-be4e-dc5e159997b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档路径\n",
    "file_path = \"./data/tesla_p40.pdf\"\n",
    "# 矢量存储路径\n",
    "db_path = \"./chroma_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5a094-d9d4-41b4-bdf8-ea91bd11e295",
   "metadata": {},
   "source": [
    "## 准备模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8762969-ad52-4406-9d23-4af86fc63bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将GOOGLE_API_KEY加载到环境变量中\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBgKE09ReHYbG2lqC_YmdsbEjF8yQGWrGM'\n",
    "# 量化模型\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# embedding.embed_query(\"hello, world!\")\n",
    "# 推理模型\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# embedding = OllamaEmbeddings(base_url=\"http://192.168.66.24:11434\", model=\"nomic-embed-text\")\n",
    "# llm = Ollama(base_url='http://192.168.66.26:11434', model=\"gemma:7b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758a375-8ef3-4c21-a77d-ffde739229b2",
   "metadata": {},
   "source": [
    "## 加载文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1b7df-b4e6-4298-8a04-5b5e726ca6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community\n",
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e4b71-1a04-4673-87c1-ccaa66df9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文档\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156775a-1bcd-4f4d-8102-3e5049da2ec6",
   "metadata": {},
   "source": [
    "## 分割文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d1da1-9c35-4ace-831b-b3a6e0105be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4aa24d-4e8c-4cd9-b9dc-84aae1c3c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b8829-6ff3-4f4f-9868-93f66382a116",
   "metadata": {},
   "source": [
    "## 量化存入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673de99-0fa5-41f6-a29e-7d86b12e2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969132b2-26c3-441e-ab9b-cae16d3fd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#量化文档存入数据库\n",
    "vectorstore_to_db = Chroma.from_documents(\n",
    "    documents = all_splits,           # Data\n",
    "    embedding = embedding,            # Embedding model\n",
    "    persist_directory = db_path       # Directory to save data\n",
    ")\n",
    "print(vectorstore_to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872ef67-e798-4ade-a3ce-1a611d5f5083",
   "metadata": {},
   "source": [
    "## 加载embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d804437-6ead-48be-b6d4-4408d736e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x7f0b7d337430>\n"
     ]
    }
   ],
   "source": [
    "vectorstore_from_db = Chroma(\n",
    "    persist_directory = db_path,         # Directory of db\n",
    "    embedding_function = embedding   # Embedding model\n",
    ")\n",
    "print(vectorstore_from_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0567ff-40ac-4659-8bde-d19165331331",
   "metadata": {},
   "source": [
    "## 问答推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a29abae-5f7e-476a-a7db-66f1ed7b0692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大显存为 24 GB。\n"
     ]
    }
   ],
   "source": [
    "# 创建prompt模板\n",
    "template = \"\"\"Answer the question a full sentence, based only on the following context and in Chinese:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "#由模板生成prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    " \n",
    "\n",
    "retriever=vectorstore_from_db.as_retriever()\n",
    "output_parser = StrOutputParser()\n",
    "query = {\"question\": \"最大显存是多少?\"}\n",
    " \n",
    "#创建chain\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": RunnablePassthrough()\n",
    "}) | prompt | llm | output_parser\n",
    " \n",
    "print(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204f702-fc6e-4069-a694-68dbb3a4431d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1390c36-6308-495e-bf1f-b28395d7d995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
